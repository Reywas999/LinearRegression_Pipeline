{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c2cffa",
   "metadata": {},
   "source": [
    "# Determining the best fitting Linear Regression model\n",
    "\n",
    "##### Steps taken:\n",
    "1. (PRELIM) Convert statistics attributes to useful measures -- eg. comment to view ratio > total number of comments or views\n",
    "2. (PRELIM) Convert other data into meaninful information that can be used in the model building\n",
    "    - convert all columns to the same dtype: float or int\n",
    "3. (PRELIM) Drop all unnecessary columns after conversions, and clean up the DF\n",
    "4. Check for multicolinearity via a correlation matrix with the predictor attributes and take necessary action\n",
    "    - alternatively, a Pairwise Scatter plot can be used to visually examine linearity\n",
    "5. Check for correlation of each predictor variable to the outcome\n",
    "6. Drop attributes that have no significant correlation (p value of pearson correlation > 0.05)\n",
    "    - If no variables display significant correlation to the outcome, try new categories/statistics\n",
    "        - If this proves ineffective, try using a different data, or adding more data if sparcity isn't a concern\n",
    "7. Split Data into predictors (X) and outcome (y)\n",
    "8. Feature Scaling of the predictor values\n",
    "9. Split into testing and training sets\n",
    "10. Fit a linear regression model with all statistically significant predictor variables from the training dataset\n",
    "11. Fit Linear, Ridge, Lasso, and ElasticNet Regression models\n",
    "12. Create a cross-validation grid-search to obtain the best model for each form of Regression\n",
    "    - obtain the best parameters for each model\n",
    "13. For each model, fit the testing data and calculate the error -- either the RSS, MAE, MSE, MAPE, MPE, or RMSE\n",
    "14. Compare all models by their error (probably RMSE is best) and select the best model\n",
    "15. (optional) to decrease model error, find more attributes, alter the existing attributes, or increase the data\n",
    "16. Use the optomised model to make predictions on new data\n",
    "\n",
    "NOTE: This file shall be created to streamline the process of deciding which linear model best fits your dataset with continuous and/or ordinal categorical values. \n",
    "\n",
    "** This file was not created to support binary predictor variables or non-ordinal categorical data. If necessary, you can create dummy variables and add them to the X - predictors after scaling is completed\n",
    "\n",
    "*** PRELIM = Preliminary steps\n",
    "\n",
    "Prerequisite: A cleaned, ready to run pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imports needed for Regression modeling\n",
    "\n",
    "import seaborn as sns # for correlation matrix/pairwise scatter plotting\n",
    "\n",
    "# The linear Regression models I'll be comparing\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # Cross validation Grid search for parameter-error optomization \n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse # The chosen cost metric for measuring and comparing model error\n",
    "\n",
    "from scipy.stats import pearsonr # Calculating P-values for correlation\n",
    "\n",
    "from sklearn.preprocessing import scale # Feature scaling/Normalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split # For testing/training set splitting\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cleaned, ready to run DF\n",
    "cleaned_df = pd.read_csv('filename.csv') # Alternatively import an xlsx, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary parameters -- after filling out these you should be able to run the rest of the notebook with no further input\n",
    "\n",
    "outcome = 'columnname' # Input the column name of your outcome variable\n",
    "test_set_size = 0.2 # Input what proportion of your data to allocate to the testing set -- 20% is standard\n",
    "random = 33 # Input a random state \n",
    "alpha_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10, 20, 40, 60, 100, 200, 300, 500] # trial alpha parameters\n",
    "params = {'alpha': alpha_values} # list of alpha to tune with the above trial numbers\n",
    "folds_number = 5 # Set the number of Cross-Validation (CV) folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d59354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually inspect the Pairwise Scatterplot for linear relationships between predictor variables\n",
    "\n",
    "# If your dataset has more than 1,000 observations, 1,000 will be set for the sample size in the pairwise scatterplot\n",
    "# as this is more than enough to assess linearity\n",
    "\n",
    "def sample_size(df):\n",
    "    if len(df) >= 1000:\n",
    "        ss = 1000\n",
    "    else:\n",
    "        ss = len(df)\n",
    "    return ss\n",
    "\n",
    "ss = sample_size(cleaned_df)\n",
    "sns.pairplot(cleaned_df.sample(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d74ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another set of pairwise scatterplots with regression lines fit for more clarity\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "g = sns.pairplot(cleaned_df, kind=\"reg\", plot_kws={'line_kws':{'color':'red'}})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix heatmap\n",
    "\n",
    "corr = cleaned_df.corr()\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(corr, cmap='cividis', annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson r p-value calculations between each predictor and the outcome\n",
    "\n",
    "def get_p_values(df):\n",
    "    p_values = {}\n",
    "    for column in df.columns:\n",
    "        correlate, p_value = pearsonr(df[outcome], df[column])\n",
    "        p_values[column] = [correlate, p_value]\n",
    "    del p_values[outcome]\n",
    "    return p_values\n",
    "        \n",
    "\n",
    "p_values = get_p_values(cleaned_df)\n",
    "p_values = pd.DataFrame.from_dict(p_values).T.rename(columns = {0:'Correlate', 1:'p_value'}).round({'Correlate': 3, 'p_value':4})\n",
    "p_values # Consider dropping all variables that have little significance (p > 0.05) in their association to the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into predictors (X) and outcome (y)\n",
    "# I automatically removed predictor variables with p-values of > 0.05, you can manually change this if you so choose\n",
    "\n",
    "significant = p_values[p_values['p_value'] <= 0.05].index.tolist()\n",
    "X = cleaned_df[significant]\n",
    "y = cleaned_df[[outcome]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9242805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling/Normalization\n",
    "\n",
    "X = pd.DataFrame(scale(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a964831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training/testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_set_size, random_state = random) \n",
    "\n",
    "# Double checking appropriate splitting by assessing sizes of test/training sets\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edefacf",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "### Basic Linear Regression with no CV/hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression() # Standard LR Model with no hyperparameters or cross-validation\n",
    "model = lm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108bdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "872127cd",
   "metadata": {},
   "source": [
    "## Ridge Regression (L2 Regularization)\n",
    "### Cross Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8596775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Ridge class\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# Creating the CV grid-search to find an optimal model\n",
    "\n",
    "grid_cv_model = GridSearchCV(estimator = ridge,\n",
    "                       param_grid = params,\n",
    "                       scoring='neg_mean_absolute_error', # Taking the negative MAE since this model is based on cost function\n",
    "                       cv = folds_number, \n",
    "                       return_train_score = True,\n",
    "                       verbose = 1)\n",
    "\n",
    "# fiting the grid-search with the training data\n",
    "\n",
    "grid_cv_model.fit(X_train, y_train)\n",
    "\n",
    "# Saving GridSearchCV results into a dataframe \n",
    "\n",
    "cv_results = pd.DataFrame(grid_cv_model.cv_results_)\n",
    "\n",
    "# cv_results head\n",
    "\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066bb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting coding -- plotting helps visualize the best alpha to minimize negative MAE values \n",
    "# changing datatype of 'param_alpha' into int for plotting\n",
    "\n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\n",
    "\n",
    "plt.title('Negative Meam Absolute Error and alpha')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Meam Absolute Error')\n",
    "plt.legend(['train score','test score'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal alpha from the model -- this should be confirmed with the above plot\n",
    "\n",
    "best_param_ridge = grid_cv_model.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick check to see if the alpha values need updating\n",
    "\n",
    "if best_param_ridge == max(alpha_values):\n",
    "    print('Consider updating the alpha parameter list for the ridge regression, as the best parameter is equal to the max alpha')\n",
    "elif best_param_ridge == min(alpha_values):\n",
    "    print('Consider updating the alpha parameter list for the ridge regression, as the best parameter is equal to the min alpha')\n",
    "else:\n",
    "    print('The best alpha parameter fit with grid-search CV is:', str(best_param_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df55127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the alpha to the best alpha parameter from the grid-search\n",
    "\n",
    "alpha = best_param_ridge\n",
    "\n",
    "# Initialising Ridge() with above alpha\n",
    "\n",
    "ridge = Ridge(alpha = alpha)\n",
    "\n",
    "#fitting the model with optimal alpha\n",
    "\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f8c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "100719c6",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "### Cross Validation and Hypermarameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Lasso()\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "#using same attributes used for Ridge tuning except estimator here would be lasso\n",
    "\n",
    "grid_cv_model = GridSearchCV(estimator = lasso,\n",
    "                       param_grid = params,\n",
    "                       scoring = 'neg_mean_absolute_error',\n",
    "                       cv = folds_number,\n",
    "                       return_train_score = True,\n",
    "                       verbose = 1)\n",
    "#fiting model_cv\n",
    "\n",
    "grid_cv_model.fit(X_train, y_train)\n",
    "\n",
    "# Saving model_cv results into a dataframe\n",
    "\n",
    "cv_results = pd.DataFrame(grid_cv_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing param_alpha datatype to float for plotting\n",
    "\n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cv_results['param_alpha'],cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'],cv_results['mean_test_score'])\n",
    "\n",
    "plt.title('Negative Meam Absolute Error and alpha')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Meam Absolute Error')\n",
    "plt.legend(['train score','test score'],loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce19cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking best alpha from model_cv\n",
    "\n",
    "best_param_lasso = grid_cv_model.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick check to see if the alpha values need updating\n",
    "\n",
    "if best_param_lasso == max(alpha_values):\n",
    "    print('Consider updating the alpha parameter list for the ridge regression, as the best parameter is equal to the max alpha')\n",
    "elif best_param_lasso == min(alpha_values):\n",
    "    print('Consider updating the alpha parameter list for the ridge regression, as the best parameter is equal to the min alpha')\n",
    "else:\n",
    "    print('The best alpha parameter fit with grid-search CV is:', str(best_param_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ad8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting alpha \n",
    "\n",
    "alpha = best_param_lasso\n",
    "\n",
    "# Defining lasso with above alpha\n",
    "\n",
    "lasso = Lasso(alpha = alpha)\n",
    "  \n",
    "# fiting lasso\n",
    "\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ebd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b688fbf",
   "metadata": {},
   "source": [
    "## ElasticNet Regression\n",
    "### Cross Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8418567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising ElasticNet()\n",
    "\n",
    "elasticnet = ElasticNet() \n",
    "\n",
    "# using same attributes used for Ridge tuning except estimator here would be ElasticNet\n",
    "\n",
    "grid_cv_model = GridSearchCV(estimator = elasticnet,\n",
    "                       param_grid = params,\n",
    "                       scoring = 'neg_mean_absolute_error',\n",
    "                       cv = folds_number,\n",
    "                       return_train_score = True,\n",
    "                       verbose = 1)\n",
    "#fitingmodel_cv\n",
    "\n",
    "grid_cv_model.fit(X_train, y_train)\n",
    "\n",
    "# Saving model_cv results into a dataframe\n",
    "\n",
    "cv_results = pd.DataFrame(grid_cv_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b73a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change param_alpha datatype to float for plotting\n",
    "\n",
    "cv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n",
    "\n",
    "# plotting\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cv_results['param_alpha'],cv_results['mean_train_score'])\n",
    "plt.plot(cv_results['param_alpha'],cv_results['mean_test_score'])\n",
    "\n",
    "plt.title('Negative Meam Absolute Error and alpha')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Negative Meam Absolute Error')\n",
    "plt.legend(['train score','test score'],loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9842f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking best  alpha from model_cv\n",
    "\n",
    "best_param_ElasticNet = grid_cv_model.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick check to see if the alpha values need updating\n",
    "\n",
    "if best_param_ElasticNet == max(alpha_values):\n",
    "    print('Consider updating the alpha parameter list for the ridge regression, as the best parameter is equal to the max alpha')\n",
    "elif best_param_ElasticNet == min(alpha_values):\n",
    "    print('Consider updating the alpha parameter list for the ridge regression, as the best parameter is equal to the min alpha')\n",
    "else:\n",
    "    print('The best alpha parameter fit with grid-search CV is:', str(best_param_ElasticNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting alpha\n",
    "\n",
    "alpha = best_param_ElasticNet\n",
    "\n",
    "# Defining ElasticNet with above alpha\n",
    "\n",
    "elasticnet = ElasticNet(alpha = alpha)\n",
    "  \n",
    "# fiting elastic net\n",
    "\n",
    "elasticnet.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfd721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a4cb44",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Compare all three optomized models via their RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192528e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using each of the fit models to predict the test set\n",
    "\n",
    "pred_by_reg = model.predict(X_test)\n",
    "pred_by_lasso =  lasso.predict(X_test)\n",
    "pred_by_ridge = ridge.predict(X_test)\n",
    "pred_by_elasticnet = elasticnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2513c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# printing the calculated RMSE for all 3 models\n",
    "\n",
    "Reg_RMSE = round(np.sqrt(mse(y_test, pred_by_reg)), 3)\n",
    "lasso_RMSE = round(np.sqrt(mse(y_test, pred_by_lasso)), 3)\n",
    "ridge_RMSE = round(np.sqrt(mse(y_test, pred_by_ridge)), 3)\n",
    "ElasticNet_RMSE = round(np.sqrt(mse(y_test, pred_by_elasticnet)), 3)\n",
    "\n",
    "print(f'Reg RMSE: {Reg_RMSE}')\n",
    "print(f'Lasso RMSE: {lasso_RMSE}')\n",
    "print(f'Ridge RMSE: {ridge_RMSE}')\n",
    "print(f'ElasticNet RMSE: {ElasticNet_RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = ['best_param_lasso','best_param_ridge','best_param_ElasticNet']\n",
    "alphas_to_vals = {}\n",
    "for alpha in alphas:\n",
    "  alphas_to_vals[alpha] = eval(alpha)\n",
    "\n",
    "all_models = {'regular':Reg_RMSE, 'lasso':lasso_RMSE, 'ridge':ridge_RMSE, 'ElasticNet':ElasticNet_RMSE}\n",
    "best_model = min(all_models, key = all_models.get)\n",
    "\n",
    "if best_model != 'regular':\n",
    "    best_param = alphas_to_vals['best_param_'+best_model]\n",
    "else:\n",
    "    best_param = 'NaN - Regular Regression has no optomized alpha'\n",
    "\n",
    "if best_param != 'NaN - Regular Regression has no optomized alpha':\n",
    "    print('The Regression that minimizes the RMSE is the', best_model, 'regression with an alpha of', best_param)\n",
    "else:\n",
    "    print('The Regression that minimizes the RMSE is the', best_model, 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98708fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DF that displays the the true vs predicted values and their percent difference\n",
    "\n",
    "preds = ['pred_by_reg', 'pred_by_lasso','pred_by_ridge','pred_by_elasticnet']\n",
    "preds_to_vals = {}\n",
    "for pred in preds:\n",
    "  preds_to_vals[pred] = eval(pred)\n",
    "\n",
    "best_model_predictions = preds_to_vals['pred_by_'+best_model]\n",
    "best_model_predictions\n",
    "\n",
    "listt = []\n",
    "for num in range(0, len(best_model_predictions.tolist())):\n",
    "    listt.append(best_model_predictions.tolist()[num][0])\n",
    "\n",
    "prediction_df = X_test.copy()\n",
    "prediction_df = prediction_df.reset_index(drop = True)\n",
    "true_vals = y_test.copy()\n",
    "true_vals = true_vals.reset_index(drop = True)\n",
    "\n",
    "prediction_df = pd.merge(prediction_df, true_vals, left_index = True, right_index = True)\n",
    "prediction_df['predicted_values'] = listt\n",
    "\n",
    "prediction_df = prediction_df.rename(columns = {outcome:'true_values'})\n",
    "prediction_df['difference_percent'] = (prediction_df['true_values'] - prediction_df['predicted_values'])/prediction_df['true_values']\n",
    "\n",
    "prediction_df = prediction_df[['true_values', 'predicted_values', 'difference_percent']]\n",
    "prediction_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = round(abs(prediction_df['difference_percent']).mean(), 3)\n",
    "max_error = round(abs(prediction_df['difference_percent']).max(), 3)\n",
    "min_error = round(abs(prediction_df['difference_percent']).min(), 3)\n",
    "std_error = round(abs(prediction_df['difference_percent']).std(), 3)\n",
    "\n",
    "print('The absolute mean percent error between the predicted and true values is:', str(mean_error))\n",
    "print('The absolute standard deviation of percent error is:', str(std_error))\n",
    "print('The absolute greatest deviation percent error is:', str(max_error))\n",
    "print('The absolute least percent error is:', str(min_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
